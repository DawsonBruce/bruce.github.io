<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bruce Dawson</title>
    <link>https://www.bruce.audio/</link>
    <description>Recent posts from on Bruce Dawson</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Feb 2025 22:20:13 -0800</lastBuildDate><atom:link href="https://www.bruce.audio/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Efficient Real-Time Synchronization in Audio Processing with std::memory_order_release and std::memory_order_acquire</title>
      <link>https://www.bruce.audio/post/2025/02/24/memory_ordering/</link>
      <pubDate>Mon, 24 Feb 2025 22:20:13 -0800</pubDate>
      
      <guid>https://www.bruce.audio/post/2025/02/24/memory_ordering/</guid>
      <description>&lt;p&gt;Thread synchronization is a fundamental challenge in real-time audio processing.&lt;/p&gt;
&lt;h1 id=&#34;efficient-real-time-synchronization-in-audio-processing-with-stdmemory_order_release-and-stdmemory_order_acquire&#34;&gt;Efficient Real-Time Synchronization in Audio Processing with &lt;code&gt;std::memory_order_release&lt;/code&gt; and &lt;code&gt;std::memory_order_acquire&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Thread synchronization is a fundamental challenge in real-time audio processing. While traditional locking mechanisms such as &lt;a href=&#34;https://en.cppreference.com/w/cpp/thread/mutex&#34;&gt;mutexes&lt;/a&gt; provide a straightforward approach to managing shared state, they introduce unacceptable overhead in real-time audio threads. Blocking operations, such as memory allocations introduced by the use of a mutex on a high-priority processing thread can lead to &lt;a href=&#34;https://www.geeksforgeeks.org/priority-inversion-what-the-heck/&#34;&gt;priority inversion&lt;/a&gt;, latency spikes, and audio dropouts.&lt;/p&gt;
&lt;p&gt;One method of addressing C++ thread synchronization in real-time processing involves using &lt;code&gt;std::atomic&lt;/code&gt; data structures. Atomics are a lightweight mechanism for data synchronization, however correct usage of memory ordering remains a common point of confusion among software engineers. While the default memory ordering behavior of &lt;code&gt;std::atomic&lt;/code&gt; is &lt;code&gt;std::memory_order_seq_cst&lt;/code&gt; (sequental consistency), which easiest to understand, it also imposes unnecessary performance costs which can be avoided. More efficient synchronization can be achieved with &lt;code&gt;std::memory_order_release&lt;/code&gt; and &lt;code&gt;std::memory_order_acquire&lt;/code&gt;, yet many developers are unfamiliar with how these memory orderings work in practice.&lt;/p&gt;
&lt;h5 id=&#34;this-blog-post-explores&#34;&gt;This blog post explores:&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Why mutexes are unsuitable for real-time audio.&lt;/li&gt;
&lt;li&gt;How &lt;code&gt;std::memory_order_release&lt;/code&gt; and &lt;code&gt;std::memory_order_acquire&lt;/code&gt; ensure safe, lock-free synchronization.&lt;/li&gt;
&lt;li&gt;Practical example of applying these concepts to real-time parameter updates in an audio engine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-mutex&#34;&gt;The Mutex&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;std::mutex&lt;/code&gt; is an excellent &lt;a href=&#34;https://cplusplus.com/reference/cstdlib/&#34;&gt;stdlib&lt;/a&gt; object for guaranteeing thread synchronization between shared data. Used in conjunction with RAII-based containers like &lt;code&gt;std::lock_guard&lt;/code&gt;, stdlib offers built-in mechanisms for guaranteeing &lt;a href=&#34;https://en.cppreference.com/w/cpp/thread/lock_guard&#34;&gt;mutual exclusion&lt;/a&gt;. While a mutex is held, no other thread can acquire the mutex until the original holder of the mutex has released its acquisition of the object, guaranteeing that only one thread modifies a resource at a time.&lt;/p&gt;
&lt;h5 id=&#34;we-keep-mutexes-out-of-the-real-time-audio-processing-thread-for-a-few-reasons&#34;&gt;We keep mutexes out of the real-time audio processing thread for a few reasons:&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;Mutexes can block the audio thread when attempting to lock a mutex that is already held by another thread.&lt;/li&gt;
&lt;li&gt;Unpredictable performance issues can occur as a result of priority inversion if a lower priority thread holds a lock that the real-time processing thread needs&lt;/li&gt;
&lt;li&gt;Mutexes introduce non-deterministic latency as a result of thread contention and scheduling, which is unacceptable for the strict timing guaranteeings of real-time audio processing.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;atomic-memory-ordering&#34;&gt;Atomic Memory Ordering&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;std::memory_order_acquire/release&lt;/code&gt; is a mechanism that allows us to tell the compiler to synchronize reads and writes happening on an atomic object utilizing these flags, while foregoing the overhead of global memory ordering (which is provided to us with the default memory ordering flag &lt;code&gt;std::memory_order_seq_cst&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;std::memory_order_seq_cst&lt;/code&gt; assumes a sequentially consistent memory ordering. For folks that may not know, threading was introduced to the C++ library via C++11. Before C++11, all C++ applications were assumed to be read from top-to-bottom, assuming a sequentially consistent ordering.&lt;/p&gt;
&lt;p&gt;Nowadays, the default behavior of &lt;code&gt;std::memory_order_seq_cst&lt;/code&gt; does provide a guaranteed memory order, which will guarantee the same value is read and written by concurrent atomic load and atomic store operations. For the sake of real-time audio processing, which needs to be non-blocking and blazingly fast, we can utilize the &lt;code&gt;std:memory_order_acquire/release&lt;/code&gt; mechanism to guarantee concurrent reads and writes produce and consume the same value, which is incredibly important for processing real-time parameter updates which are expected to happen accurately and consistently. Let&amp;rsquo;s take a look at an example:&lt;/p&gt;
&lt;h3 id=&#34;a-concise-example&#34;&gt;A Concise Example&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;lt;atomic&amp;gt;

// Shared atomic parameter
std::atomic&amp;lt;float&amp;gt; gain {1.f};

// Control thread: Updating the gain value
void updateGain(float newGain) 
{
    gain.store(newGain, std::memory_order_release);
}

// Audio thread: Reading the gain safely
float processAudio() 
{
    return gain.load(std::memory_order_acquire); // Always sees the latest update
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the example above, we have a function &lt;code&gt;updateGain(float)&lt;/code&gt; which is expected to be called from our user interface. The user interface exists on a different thread than our high-priority real-time processing thread. Our real-time processing thread calls &lt;code&gt;processAudio()&lt;/code&gt; which reads the value of our &lt;code&gt;std::atomic&amp;lt;float&amp;gt; gain&lt;/code&gt; variable. Because the real-time thread is happening &lt;em&gt;very quickly&lt;/em&gt;, it&amp;rsquo;s likely that &lt;code&gt;gain.load()&lt;/code&gt; and &lt;code&gt;gain.store()&lt;/code&gt; will be called concurrently. By utilizing &lt;code&gt;std::memory_order_release&lt;/code&gt; while calling &lt;code&gt;gain.store()&lt;/code&gt;, and &lt;code&gt;std::memory_order_acquire&lt;/code&gt; while calling &lt;code&gt;updateGain()&lt;/code&gt; from the user interface, our application will guarantee that the value seen by the &lt;code&gt;load()&lt;/code&gt; operation is the same value provided to the &lt;code&gt;store()&lt;/code&gt; operation. Modern compilers may offer ordering guarantees by way of the default memory ordering flag, but at the added cost of the overhead of the global memory order (all &lt;em&gt;all&lt;/em&gt; atomics being synchronized).&lt;/p&gt;
&lt;p&gt;It is also worth mentioning that alternate memory ordering options exist such as &lt;code&gt;std::memory_order_relaxed&lt;/code&gt; which offers &lt;em&gt;no&lt;/em&gt; guarantees of concurrency between atomics reads and writes (only atomicity is guaranteed), &lt;code&gt;std::memory_order_acq_rel&lt;/code&gt; which combines acquire and release semantics into a single operation for atomic read-modify-write operations such as variants of &lt;code&gt;std::atomic::fetch()&lt;/code&gt; and &lt;code&gt;std::atomic::exchange()&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;in-closing&#34;&gt;In Closing&lt;/h3&gt;
&lt;p&gt;By utilizing &lt;code&gt;std::memory_order_release&lt;/code&gt; and &lt;code&gt;std::memory_order_acquire&lt;/code&gt;, developers can ensure safe, low-latency data synchronization between threads without the unnecessary synchronization overhead of the default memory ordering flag &lt;code&gt;std:memory_order_seq_cst&lt;/code&gt;. The &lt;code&gt;std::memory_order_release&lt;/code&gt; and &lt;code&gt;std::memory_order_acquire&lt;/code&gt; memory orderings allow for efficient one-way data transfer, ensuring that atomic values being read and written concurrently read the same value being stored.&lt;/p&gt;
&lt;p&gt;Understanding and applying the right memory ordering strategy can make a significant impact on the performance of our real-time processes. By incorporating the strategy described in this article, developers can improve performance without sacrificing correctness, guaranteeing non-blocking high performance multi-threaded audio processing code.&lt;/p&gt;
&lt;h4 id=&#34;additional-links&#34;&gt;Additional Links&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://en.cppreference.com/w/cpp/atomic/memory_order&#34;&gt;https://en.cppreference.com/w/cpp/atomic/memory_order&lt;/a&gt;
&lt;a href=&#34;https://www.sobyte.net/post/2022-06/cpp-memory-order/&#34;&gt;https://www.sobyte.net/post/2022-06/cpp-memory-order/&lt;/a&gt;
&lt;a href=&#34;https://leanpub.com/concurrencywithmodernc&#34;&gt;https://leanpub.com/concurrencywithmodernc&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Adventures in Dithering</title>
      <link>https://www.bruce.audio/post/2022/05/26/dithering/</link>
      <pubDate>Sat, 21 May 2022 19:21:03 -0700</pubDate>
      
      <guid>https://www.bruce.audio/post/2022/05/26/dithering/</guid>
      <description>&lt;p&gt;Recently I had an opportunity to dive into the noisy world of dithering.&lt;/p&gt;
&lt;h2 id=&#34;what-is-dithering&#34;&gt;What is Dithering?&lt;/h2&gt;
&lt;p&gt;According to &lt;a href=&#34;https://en.wikipedia.org/wiki/Dither&#34;&gt;Wikipedia&lt;/a&gt;, &amp;ldquo;dither is an intentionally applied form of noise used to randomize quantization error, preventing large-scale patterns such as color banding in images.&amp;rdquo; In the case of signal processing as pertains to audio, these patterns emerge as spectral &lt;a href=&#34;https://en.wikipedia.org/wiki/Artifact_(error)&#34;&gt;artifacts&lt;/a&gt;, producing audible frequency content not found in the original audio source. Also according to Wikipedia, the word &amp;ldquo;dither&amp;rdquo; comes from the middle english verb &amp;ldquo;didderen,&amp;rdquo; meaning, &amp;ldquo;to tremble.&amp;rdquo; Dithering is the curious case where adding noise or &amp;ldquo;tremble,&amp;rdquo; to a signal provides more information &amp;ndash; what a concept!&lt;/p&gt;
&lt;p&gt;Earlier this year I was tasked with implementing a dithering algorithm at
&lt;a href=&#34;https://output.com&#34;&gt;Output&lt;/a&gt;, which is an algorithm I had yet to previously implement. In software engineering, it seems to me that common problems arise and there&amp;rsquo;s typically tried-and-true methods for solving these problems. In the case of dithering, this is also true, as there&amp;rsquo;s a number of decent dithering algorithms available in closed-source software such as &lt;a href=&#34;https://www.izotope.com/en/products/rx.html&#34;&gt;Izotope RX&lt;/a&gt;, or &lt;a href=&#34;https://www.ableton.com/en/&#34;&gt;Ableton Live&lt;/a&gt;, some of which I had difficulty finding information about online. Thanks to organizations such as &lt;a href=&#34;https://www.airwindows.com&#34;&gt;Airwindows&lt;/a&gt; and &lt;a href=&#34;https://www.audacityteam.org&#34;&gt;Audacity&lt;/a&gt;, there are some open-source implementations available which allowed me to observe how some of these algorithms, such as how &lt;a href=&#34;https://en.wikipedia.org/wiki/Triangular_distribution&#34;&gt;Triangular Probability Density Function (TPDF)&lt;/a&gt; dithering had been implemented by others.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;why-dithering&#34;&gt;Why Dithering?&lt;/h2&gt;
&lt;p&gt;Computers use what is known as an &lt;a href=&#34;https://en.wikipedia.org/wiki/Analog-to-digital_converter&#34;&gt;Analog-to-Digital Conversion (ADC)&lt;/a&gt; process to convert analog audio signals to it&amp;rsquo;s digital representation using what is known as the &lt;a href=&#34;http://www.dspguide.com/ch3/2.htm&#34;&gt;Sampling Theorem&lt;/a&gt;. A sample is a slice of a continuous audio signal, and samples are played in sequence at &lt;a href=&#34;https://www.izotope.com/en/learn/digital-audio-basics-sample-rate-and-bit-depth.html&#34;&gt;sample rate&lt;/a&gt; to form an audible signal. When sampled correctly, a continuous signal can be exactly reconstructed using its sampled equivalent. When sampling is performed incorrectly, such as when the frequency of the analog signal is greater than the &lt;a href=&#34;Sampling&#34; title=&#34;signal processing&#34;&gt;Nyquist frequency&lt;/a&gt; (one-half of the sampling rate), aliasing occurs where the frequency of the sampled data differs from the frequency of the original signal. Aliasing corrupts the sampled information causing the reconstruction of the original signal to be impossible.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note&lt;/strong&gt;: the example images in this post are displayed using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Spectrogram&#34;&gt;spectrogram&lt;/a&gt; which displays the frequency content of an audio source. The &amp;lsquo;Y&amp;rsquo; axis of the image is frequency whereas the &amp;lsquo;X&amp;rsquo; axis is time.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-is-dithering-implemented&#34;&gt;How is Dithering Implemented?&lt;/h2&gt;
&lt;p&gt;Audio signals can be digitally represented as either an integer value within a &lt;a href=&#34;https://en.wikipedia.org/wiki/Audio_bit_depth&#34;&gt;signed bit range&lt;/a&gt;, or as a floating-point value. In my case, I was dealing with floating-point values that I had to scale to their signed bit range value before adding noise to the audio signal. The number of possible integer values in the signed bit range can be calculated as:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2 ^ bitrate
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with a range of:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;bit = 2 ^ bitrate - 1

range = { -bit , bit - 1 }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the case of 16-bit bitrate, the possible number of integer values is &lt;strong&gt;65,536&lt;/strong&gt; with a range of &lt;strong&gt;-32,768 to 32,767&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Next, floating point noise is added to the audio signal in it&amp;rsquo;s signed bit representation, resulting in modulation of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Bit_numbering&#34;&gt;Least Significant Bit&lt;/a&gt;, adding noise to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Noise_floor&#34;&gt;noise floor&lt;/a&gt;, eliminating quantization errors at the cost of a nearly imperceivable addition to the noise floor of the audio signal.&lt;/p&gt;
&lt;p&gt;TPDF dithering involves the following calculation:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// range of &amp;#39;rand&amp;#39; is { -1.0, 1.0 }
(rand * rand) / N
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;which multiplies N number of random values in the floating-point signal range (-1.0 to 1.0), divided by N.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example of TPDF (silent audio source):&lt;/strong&gt;&lt;/p&gt;


&lt;img src=&#34;images/dither_tpdf.png&#34; width=&#34;100%&#34;/&gt;


&lt;p&gt;However, noise-shaped TPDF Dithering takes a slightly different approach by tracking the previous random value and subtracting it from the current random value &amp;ndash; this creates a &amp;ldquo;shaped,&amp;rdquo; effect which reduces the amount of noise distributed to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Frequency_band&#34;&gt;middle frequency bands&lt;/a&gt;.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;rand = ( rand - previous_rand )
previous_rand = rand
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Example of noise-shaped dithering (silent audio source):&lt;/strong&gt;&lt;/p&gt;


&lt;img src=&#34;images/dither_shaped_tpdf.png&#34; width=&#34;100%&#34;/&gt;


&lt;p&gt;While either dithering type is an acceptable choice, I have a preference for
noise-shaped dithering as it eliminates some noise in the mid-frequency band.
Other types of dithering such as Ableton Live&amp;rsquo;s &lt;strong&gt;POW-r&lt;/strong&gt; algorithm I have yet to explore, namely because I had difficulty finding information about these algorithms online. If you have experience implementing other types of dithering I&amp;rsquo;d love to &lt;a href=&#34;mailto:hi@bruce.audio?subject=Dithering&#34;&gt;hear your experience&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-results&#34;&gt;The Results&lt;/h2&gt;
&lt;p&gt;The difference between the dithered and non-dithered downsampled audio is evident when analyzed using a spectrogram. In the images below, the second example (no dithering) contains spectral artifacts on the right-hand side of the image, whereas the third image contains noise but no artifacts. The noise signal we&amp;rsquo;ve added to our audio source safely negates quantization errors by replacing the silence with noise while being virtually imperceivable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Original audio file:&lt;/strong&gt;&lt;/p&gt;


&lt;img src=&#34;images/dither_original.png&#34; width=&#34;100%&#34;/&gt;


&lt;p&gt;&lt;strong&gt;Downsampled audio file without dithering (notice the artifacts):&lt;/strong&gt;&lt;/p&gt;


&lt;img src=&#34;images/dither_no_dither.png&#34; width=&#34;100%&#34;/&gt;


&lt;p&gt;&lt;strong&gt;Downsampled audio file with dithering (no artifacts):&lt;/strong&gt;&lt;/p&gt;


&lt;img src=&#34;images/dither_with_dither.png&#34; width=&#34;100%&#34;/&gt;


&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The exploration of dithering was an exciting and challenging experience that aided me in growing a bit further in my skillset as an audio software engineer. While the implementation process wasn&amp;rsquo;t as seamless as I had hoped due to some issues with low frequency content I had added to the signal in my initial attempts as a result of my incorrect calculations, this exploration helped me demystify the concept of dithering and further clarify my understanding of signal processing as pertains to audio bit depth, signed integer ranges, and bit modulation. I hope this blog post helps any reader that may be currently implementing their own dithering algorithm, may be curious as to how dithering works, or is simply interested in the work that I am doing.&lt;/p&gt;
&lt;p&gt;Thanks for reading. Until next time, friends.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>How&#39;d we get here?</title>
      <link>https://www.bruce.audio/post/2022/04/23/howd_we_get_here/</link>
      <pubDate>Sat, 23 Apr 2022 21:03:02 -0700</pubDate>
      
      <guid>https://www.bruce.audio/post/2022/04/23/howd_we_get_here/</guid>
      <description>&lt;p&gt;How&amp;rsquo;d we get here, what&amp;rsquo;s the plan, and where have I been?&lt;/p&gt;
&lt;h2 id=&#34;_today-things-feel-different-and-im-okay-with-that_&#34;&gt;&lt;em&gt;today things feel different and I&amp;rsquo;m okay with that.&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;First, I&amp;rsquo;d like to welcome you and mention that I plan to use this space to provide life updates on occasion, discuss interesting engineering problems I am solving, and deep-dive into digital audio topics. Subscribe via &lt;a href=&#34;mailto:hi@bruce.audio?subject=I%20want%20to%20subscribe!&#34;&gt;email&lt;/a&gt; or &lt;a href=&#34;https://www.bruce.audio/index.xml&#34;&gt;RSS&lt;/a&gt; if you&amp;rsquo;d like to receive automatic updates when I create new posts on this blog. Second, I&amp;rsquo;d like to address that I spent the past few months radio-silent on social media after finding myself in deep need of a &lt;a href=&#34;https://health.clevelandclinic.org/digital-detox/&#34;&gt;digital detox&lt;/a&gt; and a desire to find some balance in my life.&lt;/p&gt;
&lt;p&gt;The past six months of my life has been interesting. For over a decade I spent so much of my time
dedicated to my craft of playing music &amp;ndash; primarily electronic music in the form of
techno and psy-trance. While I&amp;rsquo;ll always have a natural affinity for this type of music, I haven&amp;rsquo;t
found playing music to be the primary source of fulfillment that it once was. It&amp;rsquo;ll always
remain a part of me, but somehow, today things feel different and I&amp;rsquo;m okay with that.&lt;/p&gt;
&lt;h2 id=&#34;_i-had-to-make-a-decision_&#34;&gt;&lt;em&gt;I had to make a decision.&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;For years, I had been striving toward an ideal fantasy of being a globetrotting DJ while having a family and thriving in my professional career as a software engineer. My music career would fluctuate over the years, as I&amp;rsquo;d play a number of events each festival season &amp;ndash;
mostly locally, but some bookings would occur in nearby states (including a few times playing in Mexico). It dawned on me one day that in order to thrive as a performing musician, one must give it a
full-hearted effort (no shit, right?). Admittedly, I hadn&amp;rsquo;t been as invested in the craft as my peers and I knew it. Conversely, it had also dawned on me that I had a considerable amount of opportunity in front of me as a software engineer. This opportunity, also admittedly, had been taken for granted.&lt;/p&gt;
&lt;p&gt;In retrospect, I had spent far too much time paralyzed at the notion of choosing a
direction upon encountering this existential fork-in-the-road, letting both crafts suffer equally.
Of course, there is time for both pursuits (with enough sacrifice), however, it seldom felt this way. Occasionally, I would manically attempt to jump-start my music career in moments of fleeting inspiration, struggling to launch from the ground level and evade the &lt;a href=&#34;https://dictionary.cambridge.org/us/dictionary/english/gatekeeping&#34;&gt;gatekeepers&lt;/a&gt;, all the while doing nothing to take true ownership over the professional opportunities directly in front of me within my engineering career. These opportunities beckoned for my attention. I had to make a decision.&lt;/p&gt;
&lt;p&gt;While doing this soul-searching I had realized that both of these crafts that I am deeply
passionate about required a thorough effort to thrive in their respective domains. I had seen
that, while I continued to pursue my ambitions of being a musician, the sheer amount of work
that goes into becoming a successful musician parallels (and in a lot of way, exceeds) the amount of effort it takes to be a successful software engineer and contributor to the tech community. One of these crafts involves late-night networking in smokey downtown warehouses, bars, and clubs, weekend-after-weekend while the other requires community involvement through open-source contributions, technical talks, mentorship, and so forth. Either choice is going to be difficult, but which choice brings the truest sense of fulfillment?&lt;/p&gt;
&lt;h2 id=&#34;_the-only-thing-ive-known-and-loved-longer-in-my-life-than-electronic-music-is-programming_&#34;&gt;&lt;em&gt;The only thing I&amp;rsquo;ve known and loved longer in my life than electronic music is programming.&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;I had also started therapy in these months of radio-silence, found some tools that work for me, and turned my attention inward. I&amp;rsquo;ve found it deeply impactful and has really helped me reframe the
inner-dialog around what brings me true fulfillment. While I&amp;rsquo;ll always love music, and I&amp;rsquo;ll happily share it with others when the opportunity is right, I also know where my heart is invested, and I know what keeps the creative flame alive inside. The only thing I&amp;rsquo;ve known and loved longer in my life than electronic music is programming. Today, pursing this path of realizing my potential as a software engineer with a full-hearted effort is invigorating. Today, taking ownership over the opportunities staring me in the face is fulfilling. Doing what I can to &lt;a href=&#34;https://www.kadenze.com/programs/output-teaches-creating-audio-plugins-with-c-and-juce&#34;&gt;lower the bar to entry&lt;/a&gt; for my peers brings me so much satisfaction.&lt;/p&gt;
&lt;h2 id=&#34;_it-was-a-revealing-humbling-and-impactful-exploration_&#34;&gt;&lt;em&gt;It was a revealing, humbling, and impactful exploration..&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Lastly, toward the end of last year I decided to dive head-first in relearning the fundamentals of
computer science. Why would I do that? Well, I wanted to take ownership over the knowledge gaps in my understanding and do a thorough pass through all the information I should be expected to know &amp;ndash;  fundamental data structures, algorithms, design patterns, asymptotic complexity, and so on. It was a revealing, humbling, and impactful exploration, one of which I will dive into further in-depth here in an upcoming post.&lt;/p&gt;
&lt;p&gt;Until then friends, thanks for reading.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
